{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I ran this notebook on Kaggle. It can be accessed at: \n",
    "# https://www.kaggle.com/abdelrhmanghreeb/classification-using-pca-on-pima-data-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pima-indians-diabetes.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "from subprocess import check_output\n",
    "print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = np.loadtxt('../input/pima-indians-diabetes.csv', delimiter=\",\")\n",
    "#split data into X (the 8 features) and Y (the label)\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#subtract the mean from your data: X = X - X.mean(axis=1).reshape(-1, 1)\n",
    "xAdjusted = X- X.mean(axis=1, keepdims=True) #This is done inside the covar calculations\n",
    "X = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calcCovMatrixEntry(xx, yy):\n",
    "    xx = xx-xx.mean(axis=0, keepdims=True)\n",
    "    yy = yy-yy.mean(axis=0, keepdims=True)\n",
    "    return ((np.sum(xx*yy))/(xx.shape[0]-1)) #cov(xx,yy)\n",
    "def calcCovMatrix(xxx):\n",
    "    cm = np.empty([xxx.shape[0],xxx.shape[0]])\n",
    "\n",
    "    for i in range(xxx.shape[0]):\n",
    "        for j in range(xxx.shape[0]):\n",
    "            cm[i][j]=calcCovMatrixEntry(xxx[i],xxx[j])\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 768)\n",
      "(8, 8)\n",
      "w=  8\n",
      "v=  (8, 8)\n"
     ]
    }
   ],
   "source": [
    "#calculate the covariance matrix of the 8 features MAUALLY\n",
    "#xxx = np.array([[-2.1, -1,  4.3],[3,  1.1,  0.12]])\n",
    "covMatrix = calcCovMatrix(X)\n",
    "print (X.shape)\n",
    "print (covMatrix.shape)\n",
    "#calculate the eigenvectors\n",
    "from numpy import linalg as LA\n",
    "w, v = LA.eig(covMatrix) #w= eigenvalues, v=eigenvectors\n",
    "print ('w= ', len(w))\n",
    "print ('v= ', v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.02176587e-03   2.26488861e-02  -2.24649003e-02  -4.90459604e-02\n",
      "   -1.51612874e-01  -5.04730888e-03   9.86672995e-01  -6.10123250e-03]\n",
      " [  9.78115765e-02   9.72210040e-01   1.43428710e-01   1.19830016e-01\n",
      "    8.79407680e-02   5.07391813e-02   8.83426114e-04   8.25459539e-04]\n",
      " [  1.60930503e-02   1.41909330e-01  -9.22467192e-01  -2.62742788e-01\n",
      "    2.32165009e-01   7.56365525e-02  -1.22975947e-03  -5.20865450e-04]\n",
      " [  6.07566861e-02  -5.78614699e-02  -3.07013055e-01   8.84369380e-01\n",
      "   -2.59973487e-01   2.21363068e-01  -3.76444746e-04   2.54871909e-03]\n",
      " [  9.93110844e-01  -9.46266913e-02   2.09773019e-02  -6.55503615e-02\n",
      "    1.72312241e-04  -6.13326472e-03   1.42307394e-03   2.68965921e-04]\n",
      " [  1.40108085e-02   4.69729766e-02  -1.32444542e-01   1.92801728e-01\n",
      "   -2.14744823e-02  -9.70776708e-01  -2.73046214e-03   2.67341863e-03]\n",
      " [  5.37167919e-04   8.16804621e-04  -6.39983017e-04   2.69908637e-03\n",
      "   -1.64080684e-03  -2.02903702e-03  -6.34402965e-03  -9.99972146e-01]\n",
      " [ -3.56474430e-03   1.40168181e-01  -1.25454310e-01  -3.01024330e-01\n",
      "   -9.20504903e-01  -1.51133239e-02  -1.62555343e-01   1.95271966e-03]]\n"
     ]
    }
   ],
   "source": [
    "#order the eigenvectors by eigenvalues\n",
    "w = np.array(w)\n",
    "sortedV = np.empty(v.shape)\n",
    "j =0\n",
    "\n",
    "for i in w.argsort()[::-1]:\n",
    "    sortedV[j] =v[i]\n",
    "    j += 1\n",
    "print (sortedV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#construct the feature vector\n",
    "def getReducedData(number_of_eigenvectors_to_consider):\n",
    "    feature_vector = sortedV[:number_of_eigenvectors_to_consider]\n",
    "\n",
    "    #projection: deriving the new dataset with reduced dimensionality\n",
    "    reducedData = np.dot(feature_vector,xAdjusted.T)\n",
    "    return reducedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.71223022  0.71942446  0.70289855  0.76086957  0.7080292 ]\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "model = xgboost.XGBClassifier() #use the gradient boosted decision trees\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X_train, y_train, cv=5) #use 5 folds\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Cross Validation Accuracy: 0.72 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.13%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_using_PCA(num_of_eigenvectors_to_use):\n",
    "    X_reduced = getReducedData(num_of_eigenvectors_to_use)\n",
    "    print (X_reduced.shape)\n",
    "    print (Y.shape)\n",
    "    #split data (X, Y) into train and test sets \n",
    "    seed = 7 #A random permutation, to split the data randomly\n",
    "    test_size = 0.1\n",
    "    X_train , X_test, y_train, y_test= cross_validation.train_test_split(X_reduced.T,Y,test_size=test_size,random_state=seed)\n",
    "    model = xgboost.XGBClassifier() #use the gradient boosted decision trees\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5) #use 5 folds\n",
    "    return(\"Used Eigen Vectors: %d Average Cross Validation Accuracy: %0.2f (+/- %0.2f)\" % (num_of_eigenvectors_to_use, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 768)\n",
      "(768,)\n",
      "Used Eigen Vectors: 1 Average Cross Validation Accuracy: 0.65 (+/- 0.03)\n",
      "(2, 768)\n",
      "(768,)\n",
      "Used Eigen Vectors: 2 Average Cross Validation Accuracy: 0.72 (+/- 0.04)\n",
      "(3, 768)\n",
      "(768,)\n",
      "Used Eigen Vectors: 3 Average Cross Validation Accuracy: 0.73 (+/- 0.03)\n",
      "(4, 768)\n",
      "(768,)\n",
      "Used Eigen Vectors: 4 Average Cross Validation Accuracy: 0.73 (+/- 0.03)\n",
      "(5, 768)\n",
      "(768,)\n",
      "Used Eigen Vectors: 5 Average Cross Validation Accuracy: 0.73 (+/- 0.03)\n",
      "(6, 768)\n",
      "(768,)\n",
      "Used Eigen Vectors: 6 Average Cross Validation Accuracy: 0.74 (+/- 0.04)\n",
      "(7, 768)\n",
      "(768,)\n",
      "Used Eigen Vectors: 7 Average Cross Validation Accuracy: 0.74 (+/- 0.05)\n",
      "(8, 768)\n",
      "(768,)\n",
      "Used Eigen Vectors: 8 Average Cross Validation Accuracy: 0.74 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print (classify_using_PCA(i+1))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768L, 2L)\n",
      "(768L, 8L)\n",
      "(768L,)\n",
      "3407.40378064\n",
      "4309.1660389\n"
     ]
    }
   ],
   "source": [
    "X_reduced = getReducedData(2).T\n",
    "print (X_reduced.shape)\n",
    "print (X.shape)\n",
    "print (Y.shape)\n",
    "\n",
    "print np.var(X)\n",
    "print np.var(X_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Eigen Vectors: 1, Variance: 0.88855\n",
      "Used Eigen Vectors: 2, Variance: 0.95014\n",
      "Used Eigen Vectors: 3, Variance: 0.97593\n",
      "Used Eigen Vectors: 4, Variance: 0.98901\n",
      "Used Eigen Vectors: 5, Variance: 0.99645\n",
      "Used Eigen Vectors: 6, Variance: 0.99948\n",
      "Used Eigen Vectors: 7, Variance: 0.99999\n",
      "Used Eigen Vectors: 8, Variance: 1.00000\n"
     ]
    }
   ],
   "source": [
    "# calculating variance\n",
    "for i in range(8):\n",
    "    print (\"Used Eigen Vectors: %d, Variance: %0.5f\" %  (i+1,(np.sum(w[:i+1]))/(np.sum(w))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
